from tensorflow import keras
from tensorflow.keras.preprocessing import sequence
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding
from tensorflow.keras.layers import SimpleRNN
from tensorflow.keras.datasets import imdb
from tensorflow.keras import initializers

max_features=20000
max_len=30
batch_size=32
(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=max_features)

x_train=sequence.pad_sequences(x_train,maxlen=max_len)
x_test=sequence.pad_sequences(x_test,maxlen=max_len)


#Vanilla RNN

rnn_hidden_dim=5
word_embedding_dim=50
model_rnn=Sequential()
model_rnn.add(Embedding(max_features,word_embedding_dim))
model_rnn.add(SimpleRNN(rnn_hidden_dim,kernel_initializer=initializers.RandomNormal(stddev=0.001),
           recurrent_initializer=initializers.Identity(gain=1.0),
           activation="relu", input_shape=x_train.shape[1:]))
model_rnn.add(Dense(1,activation="sigmoid"))

rmsprop=keras.optimizers.RMSprop(lr=0.001)
model_rnn.compile(loss="binary_crossentropy",optimizer=rmsprop,metrics=["accuracy"])
model_rnn.fit(x_train,y_train,batch_size=batch_size, epochs=10,validation_data=(x_test,y_test))

score,acc=model_rnn.evaluate(x_test,y_test,batch_size=batch_size)
